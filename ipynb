# ==================== BASIC IMPORTS ====================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor

# Plot styling
sns.set(style="whitegrid", context="talk")

# ==================== LOAD DATA ====================
csv_path = "/content/Parametric_Sweep_Loss_Table.csv"  # path to your dataset
df = pd.read_csv(csv_path)

print("Dataset Columns:")
print(df.columns)
df.head()

# ==================== DEFINE FEATURES AND TARGET ====================
target_col = "SolidLoss [W]"  # output variable
feature_cols = [c for c in df.columns if c != target_col]

X = df[feature_cols]
y = df[target_col]

# 50% training, 50% testing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.5, random_state=42
)

print(f"Train size: {X_train.shape}, Test size: {X_test.shape}")

# ==================== GRID SEARCH FOR GRADIENT BOOSTING ====================
gb_base = GradientBoostingRegressor(random_state=42)

gb_param_grid = {
    "learning_rate": [0.05, 0.1],
    "n_estimators": [300, 600],
    "max_depth": [2, 3],
    "subsample": [0.8, 1.0],
}

gb_grid = GridSearchCV(
    estimator=gb_base,
    param_grid=gb_param_grid,
    cv=3,
    scoring="r2",
    n_jobs=-1,
    verbose=1
)

# ==================== DEFINE MODELS ====================
models = {
    "Linear Regression": Pipeline([
        ("scaler", StandardScaler()),
        ("reg", LinearRegression())
    ]),

    "Polynomial (2nd order)": make_pipeline(
        StandardScaler(),
        PolynomialFeatures(degree=2, include_bias=False),
        LinearRegression()
    ),

    "SVR (RBF)": Pipeline([
        ("scaler", StandardScaler()),
        ("reg", SVR(kernel="rbf", C=10, epsilon=0.1))
    ]),

    "KNN Regressor": Pipeline([
        ("scaler", StandardScaler()),
        ("reg", KNeighborsRegressor(n_neighbors=5))
    ]),

    "Random Forest": RandomForestRegressor(
        n_estimators=300, random_state=42, n_jobs=-1
    ),

    "Gradient Boosting (tuned)": gb_grid,
}

# ==================== TRAIN AND EVALUATE ====================
results = []

for name, model in models.items():
    print(f"\n=== Training model: {name} ===")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    results.append({"Model": name, "RMSE": rmse, "R2": r2})

    if hasattr(model, "best_params_"):
        print(f"Best hyperparameters for {name}:")
        print(model.best_params_)

results_df = pd.DataFrame(results).sort_values("R2", ascending=False)
results_df

plt.figure(figsize=(8, 8))
sns.barplot(data=results_df, x="Model", y="R2")
plt.xticks(rotation=45, ha="right")
plt.title("Model Comparison - R²")
plt.tight_layout()
plt.show()

svr_model = models["SVR (RBF)"]
y_pred_svr = svr_model.predict(X_test)

plt.figure(figsize=(7, 7))
sns.scatterplot(x=y_test, y=y_pred_svr)

min_val = min(y_test.min(), y_pred_svr.min())
max_val = max(y_test.max(), y_pred_svr.max())
plt.plot([min_val, max_val], [min_val, max_val], "--")

plt.xlabel("True SolidLoss [W]")
plt.ylabel("Predicted SolidLoss [W]")
plt.title("SVR (RBF) — True vs Predicted")
plt.tight_layout()
plt.show()

top3 = results_df.head(3)["Model"].tolist()

for name in top3:
    model = models[name]
    y_pred = model.predict(X_test)

    plt.figure(figsize=(7, 7))
    sns.scatterplot(x=y_test, y=y_pred)

    min_val = min(y_test.min(), y_pred.min())
    max_val = max(y_test.max(), y_pred.max())
    plt.plot([min_val, max_val], [min_val, max_val], "--")

    plt.title(f"True vs Predicted - {name}")
    plt.xlabel("True Loss")
    plt.ylabel("Predicted Loss")
    plt.tight_layout()
    plt.show()

